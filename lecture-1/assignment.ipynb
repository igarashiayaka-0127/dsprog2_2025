{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdee695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "スクレイピングを開始します...\n",
      "------------------------------------------------------------\n",
      "No.  | リポジトリ名                         | 言語         | スター数\n",
      "------------------------------------------------------------\n",
      "1    | material-design-icons          | Unknown    | 53k\n",
      "2    | guava                          | Java       | 51k\n",
      "3    | zx                             | JavaScript | 45k\n",
      "4    | styleguide                     | HTML       | 39k\n",
      "5    | leveldb                        | C++        | 38k\n",
      "6    | googletest                     | C++        | 37k\n",
      "7    | comprehensive-rust             | Rust       | 32k\n",
      "8    | material-design-lite           | HTML       | 32k\n",
      "9    | python-fire                    | Python     | 28k\n",
      "10   | flatbuffers                    | C++        | 25k\n",
      "11   | gson                           | Java       | 24k\n",
      "12   | ExoPlayer                      | Java       | 22k\n",
      "13   | iosched                        | Kotlin     | 22k\n",
      "14   | eng-practices                  | Unknown    | 20k\n",
      "15   | fonts                          | HTML       | 19k\n",
      "16   | filament                       | C++        | 19k\n",
      "17   | cadvisor                       | Go         | 19k\n",
      "18   | web-starter-kit                | HTML       | 18k\n",
      "19   | flexbox-layout                 | Kotlin     | 18k\n",
      "20   | dagger                         | Java       | 18k\n",
      "------------------------------------------------------------\n",
      "スクレイピング完了: 20 件取得しました。\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "def scrape_google_repos_complete():\n",
    "    url = \"https://github.com/orgs/google/repositories?q=&type=all&language=&sort=stargazers\"\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n",
    "    }\n",
    "\n",
    "    print(\"スクレイピングを開始します...\")\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"アクセスエラー: {e}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # ★実績のある「h3タグ」から攻める（これが一番確実）\n",
    "    all_h3 = soup.find_all('h3')\n",
    "    \n",
    "    data_list = []\n",
    "    count = 0\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'No.':<4} | {'リポジトリ名':<30} | {'言語':<10} | {'スター数'}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for h3 in all_h3:\n",
    "        # h3の中のリンクを取得\n",
    "        a_tag = h3.find('a')\n",
    "        if not a_tag: continue\n",
    "        \n",
    "        # Googleのリポジトリじゃないリンク（ナビゲーションなど）は無視\n",
    "        href = a_tag.get('href', '')\n",
    "        if not href.strip().startswith('/google/'): continue\n",
    "            \n",
    "        name = a_tag.text.strip()\n",
    "        \n",
    "        # 親要素（行全体）を取得\n",
    "        parent = h3.find_parent('li')\n",
    "        \n",
    "        # もしliが親じゃなかった場合（divなどの場合）、もっと上の階層を探す\n",
    "        if not parent:\n",
    "            parent = h3.find_parent('div', class_='Box-row')\n",
    "        if not parent: # それでもなければh3の親の親を使う\n",
    "            parent = h3.parent.parent\n",
    "        \n",
    "        # --- 言語取得ロジック（あなたの発見を取り入れました！） ---\n",
    "        language = \"Unknown\"\n",
    "        \n",
    "        if parent:\n",
    "            # 1. まず「色のついた丸ポチ」があるか探す（これが一番正確）\n",
    "            color_dot = parent.find('span', style=lambda s: s and 'background-color' in s)\n",
    "            \n",
    "            if color_dot:\n",
    "                # 丸ポチの親のテキストを取る\n",
    "                language = color_dot.parent.text.strip()\n",
    "            else:\n",
    "                # 2. 丸ポチがない場合、あなたが発見したクラス名を探す\n",
    "                # \"ReposListItem-module__Text\" を含むタグを全部探す\n",
    "                target_spans = parent.find_all('span', class_=lambda c: c and 'ReposListItem-module__Text' in c)\n",
    "                \n",
    "                for span in target_spans:\n",
    "                    text = span.text.strip()\n",
    "                    # 「Updated」や「License」ではなく、かつ数字だけでもないものを言語とみなす\n",
    "                    if \"Updated\" not in text and \"License\" not in text and not text.isdigit() and len(text) < 20:\n",
    "                        language = text\n",
    "                        break\n",
    "\n",
    "        # --- スター数取得 ---\n",
    "        stars = \"0\"\n",
    "        # \"Stargazers\" または \"stars\" を含むリンクを探す\n",
    "        star_tag = parent.find('a', href=lambda x: x and 'stargazers' in x)\n",
    "        if star_tag:\n",
    "            stars = star_tag.text.strip().replace(',', '')\n",
    "        else:\n",
    "            # 新デザイン対応：aria-labelにstarが含まれるものを探す\n",
    "            star_span = parent.find('span', id=lambda x: x and 'star' in x)\n",
    "            if star_span:\n",
    "                stars = star_span.text.strip().replace(',', '')\n",
    "\n",
    "        # データの整形\n",
    "        language = language.replace('\\n', '').strip()\n",
    "        \n",
    "        # 表示\n",
    "        print(f\"{count+1:<4} | {name:<30} | {language:<10} | {stars}\")\n",
    "        data_list.append((name, language, stars))\n",
    "        \n",
    "        time.sleep(1)\n",
    "        count += 1\n",
    "        if count >= 20: break\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"スクレイピング完了: {len(data_list)} 件取得しました。\")\n",
    "    return data_list\n",
    "\n",
    "# 実行\n",
    "scraped_data = scrape_google_repos_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e0918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def scrape_google_repos_all():\n",
    "    # ベースとなるURL（ページ番号以外）\n",
    "    base_url = \"https://github.com/orgs/google/repositories?q=&type=all&language=&sort=stargazers\"\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n",
    "    }\n",
    "\n",
    "    all_data = []\n",
    "    page = 1\n",
    "    \n",
    "    max_pages = 100\n",
    "\n",
    "    print(f\"スクレイピングを開始します（最大 {max_pages} ページまで取得）...\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'No.':<4} | {'リポジトリ名':<30} | {'言語':<10} | {'スター数'}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    total_count = 0\n",
    "\n",
    "    # ページをめくるループ\n",
    "    while page <= max_pages:\n",
    "        print(f\"\\n--- {page}ページ目を読み込み中 ---\")\n",
    "        \n",
    "        # URLに &page=ページ番号 をつける\n",
    "        target_url = f\"{base_url}&page={page}\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(target_url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "        except Exception as e:\n",
    "            print(f\"ページ取得エラー: {e}\")\n",
    "            break\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # リポジトリ名（h3）を取得\n",
    "        all_h3 = soup.find_all('h3')\n",
    "        \n",
    "        # もしこのページにリポジトリがなければ終了（最後のページ）\n",
    "        if not all_h3:\n",
    "            print(\"これ以上リポジトリがありません。終了します。\")\n",
    "            break\n",
    "            \n",
    "        items_on_page = 0\n",
    "\n",
    "        for h3 in all_h3:\n",
    "            a_tag = h3.find('a')\n",
    "            if not a_tag: continue\n",
    "            href = a_tag.get('href', '')\n",
    "            if not href.strip().startswith('/google/'): continue\n",
    "                \n",
    "            name = a_tag.text.strip()\n",
    "            \n",
    "            # 親要素を探す\n",
    "            parent = h3.find_parent('li')\n",
    "            if not parent: parent = h3.find_parent('div', class_='Box-row')\n",
    "            if not parent: parent = h3.parent.parent\n",
    "            \n",
    "            language = \"Unknown\"\n",
    "            stars = \"0\"\n",
    "            \n",
    "            if parent:\n",
    "                # 言語取得\n",
    "                color_dot = parent.find('span', style=lambda s: s and 'background-color' in s)\n",
    "                if color_dot:\n",
    "                    language = color_dot.parent.text.strip()\n",
    "                else:\n",
    "                    target_spans = parent.find_all('span', class_=lambda c: c and 'ReposListItem-module__Text' in c)\n",
    "                    for span in target_spans:\n",
    "                        text = span.text.strip()\n",
    "                        if \"Updated\" not in text and \"License\" not in text and not text.isdigit() and len(text) < 20:\n",
    "                            language = text\n",
    "                            break\n",
    "\n",
    "                # スター数取得\n",
    "                star_tag = parent.find('a', href=lambda x: x and 'stargazers' in x)\n",
    "                if star_tag:\n",
    "                    stars = star_tag.text.strip().replace(',', '')\n",
    "                else:\n",
    "                    star_span = parent.find('span', id=lambda x: x and 'star' in x)\n",
    "                    if star_span:\n",
    "                        stars = star_span.text.strip().replace(',', '')\n",
    "\n",
    "            language = language.replace('\\n', '').strip()\n",
    "            \n",
    "            # 表示とリスト追加\n",
    "            total_count += 1\n",
    "            print(f\"{total_count:<4} | {name:<30} | {language:<10} | {stars}\")\n",
    "            all_data.append((name, language, stars))\n",
    "            \n",
    "            items_on_page += 1\n",
    "            \n",
    "            # ★ここ大事！1件ごとに1秒待つ（課題ルール）\n",
    "            time.sleep(1)\n",
    "        \n",
    "        # もしこのページで何も取れなかったら終了\n",
    "        if items_on_page == 0:\n",
    "            print(\"データが見つかりませんでした。終了します。\")\n",
    "            break\n",
    "            \n",
    "        # 次のページへ\n",
    "        page += 1\n",
    "        # ページ遷移の間にも少し休憩（サーバー負荷軽減）\n",
    "        time.sleep(2)\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"全処理完了: 合計 {len(all_data)} 件取得しました。\")\n",
    "    return all_data\n",
    "\n",
    "# 実行\n",
    "scraped_data = scrape_google_repos_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
